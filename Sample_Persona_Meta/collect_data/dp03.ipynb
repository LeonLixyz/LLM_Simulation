{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved us_dp03.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Update the URL to fetch DP02 data\n",
    "data_url = \"https://api.census.gov/data/2023/acs/acs1/profile?get=group(DP03)&for=us:1\"\n",
    "response = requests.get(data_url)\n",
    "raw_data = response.json()\n",
    "\n",
    "metadata_url = \"https://api.census.gov/data/2023/acs/acs1/profile/variables.json\"\n",
    "metadata_response = requests.get(metadata_url)\n",
    "variables = metadata_response.json()['variables']\n",
    "\n",
    "# Update the mapping to filter for DP02 variables\n",
    "dp03_mapping = {}\n",
    "for var_code, var_info in variables.items():\n",
    "    if var_code.startswith('DP03'):  # Only DP02 group variables\n",
    "        dp03_mapping[var_code] = var_info['label']\n",
    "\n",
    "variable_codes = raw_data[0]\n",
    "values = raw_data[1]\n",
    "\n",
    "data_df = pd.DataFrame({\n",
    "    \"Variable Code\": variable_codes,\n",
    "    \"Value\": values\n",
    "})\n",
    "\n",
    "data_df['Label'] = data_df['Variable Code'].map(dp03_mapping)\n",
    "\n",
    "data_df = data_df[['Label', 'Value']].dropna()\n",
    "\n",
    "import os\n",
    "# Ensure the raw data directory exists\n",
    "raw_data_dir = \"/user/al4263/Simulate/Persona/data/DP03/raw_data\"\n",
    "os.makedirs(raw_data_dir, exist_ok=True)\n",
    "\n",
    "# Save the nationwide data\n",
    "filename = \"us_dp03.csv\"\n",
    "data_df.to_csv(os.path.join(raw_data_dir, filename), index=False)\n",
    "print(f\"Saved {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Alabama...\n",
      "Saved al_dp03.csv\n",
      "Processing Alaska...\n",
      "Saved ak_dp03.csv\n",
      "Processing Arizona...\n",
      "Saved az_dp03.csv\n",
      "Processing Arkansas...\n",
      "Saved ar_dp03.csv\n",
      "Processing California...\n",
      "Saved ca_dp03.csv\n",
      "Processing Colorado...\n",
      "Saved co_dp03.csv\n",
      "Processing Connecticut...\n",
      "Saved ct_dp03.csv\n",
      "Processing Delaware...\n",
      "Saved de_dp03.csv\n",
      "Processing Florida...\n",
      "Saved fl_dp03.csv\n",
      "Processing Georgia...\n",
      "Saved ga_dp03.csv\n",
      "Processing Hawaii...\n",
      "Saved hi_dp03.csv\n",
      "Processing Idaho...\n",
      "Saved id_dp03.csv\n",
      "Processing Illinois...\n",
      "Saved il_dp03.csv\n",
      "Processing Indiana...\n",
      "Saved in_dp03.csv\n",
      "Processing Iowa...\n",
      "Saved ia_dp03.csv\n",
      "Processing Kansas...\n",
      "Saved ks_dp03.csv\n",
      "Processing Kentucky...\n",
      "Saved ky_dp03.csv\n",
      "Processing Louisiana...\n",
      "Saved la_dp03.csv\n",
      "Processing Maine...\n",
      "Saved me_dp03.csv\n",
      "Processing Maryland...\n",
      "Saved md_dp03.csv\n",
      "Processing Massachusetts...\n",
      "Saved ma_dp03.csv\n",
      "Processing Michigan...\n",
      "Saved mi_dp03.csv\n",
      "Processing Minnesota...\n",
      "Saved mn_dp03.csv\n",
      "Processing Mississippi...\n",
      "Saved ms_dp03.csv\n",
      "Processing Missouri...\n",
      "Saved mo_dp03.csv\n",
      "Processing Montana...\n",
      "Saved mt_dp03.csv\n",
      "Processing Nebraska...\n",
      "Saved ne_dp03.csv\n",
      "Processing Nevada...\n",
      "Saved nv_dp03.csv\n",
      "Processing New Hampshire...\n",
      "Saved nh_dp03.csv\n",
      "Processing New Jersey...\n",
      "Saved nj_dp03.csv\n",
      "Processing New Mexico...\n",
      "Saved nm_dp03.csv\n",
      "Processing New York...\n",
      "Saved ny_dp03.csv\n",
      "Processing North Carolina...\n",
      "Saved nc_dp03.csv\n",
      "Processing North Dakota...\n",
      "Saved nd_dp03.csv\n",
      "Processing Ohio...\n",
      "Saved oh_dp03.csv\n",
      "Processing Oklahoma...\n",
      "Saved ok_dp03.csv\n",
      "Processing Oregon...\n",
      "Saved or_dp03.csv\n",
      "Processing Pennsylvania...\n",
      "Saved pa_dp03.csv\n",
      "Processing Rhode Island...\n",
      "Saved ri_dp03.csv\n",
      "Processing South Carolina...\n",
      "Saved sc_dp03.csv\n",
      "Processing South Dakota...\n",
      "Saved sd_dp03.csv\n",
      "Processing Tennessee...\n",
      "Saved tn_dp03.csv\n",
      "Processing Texas...\n",
      "Saved tx_dp03.csv\n",
      "Processing Utah...\n",
      "Saved ut_dp03.csv\n",
      "Processing Vermont...\n",
      "Saved vt_dp03.csv\n",
      "Processing Virginia...\n",
      "Saved va_dp03.csv\n",
      "Processing Washington...\n",
      "Saved wa_dp03.csv\n",
      "Processing West Virginia...\n",
      "Saved wv_dp03.csv\n",
      "Processing Wisconsin...\n",
      "Saved wi_dp03.csv\n",
      "Processing Wyoming...\n",
      "Saved wy_dp03.csv\n",
      "All states processed successfully!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "import us\n",
    "\n",
    "def get_state_data(state_fips):\n",
    "    data_url = f\"https://api.census.gov/data/2023/acs/acs1/profile?get=group(DP03)&for=state:{state_fips}\"\n",
    "    response = requests.get(data_url)\n",
    "    return response.json()\n",
    "\n",
    "metadata_url = \"https://api.census.gov/data/2023/acs/acs1/profile/variables.json\"\n",
    "metadata_response = requests.get(metadata_url)\n",
    "variables = metadata_response.json()['variables']\n",
    "\n",
    "dp03_mapping = {}\n",
    "for var_code, var_info in variables.items():\n",
    "    if var_code.startswith('DP03'):  \n",
    "        dp03_mapping[var_code] = var_info['label']\n",
    "\n",
    "# Ensure the raw data directory exists\n",
    "raw_data_dir = \"/user/al4263/Simulate/Persona/data/DP03/raw_data\"\n",
    "os.makedirs(raw_data_dir, exist_ok=True)\n",
    "\n",
    "for state in us.states.STATES:\n",
    "    print(f\"Processing {state.name}...\")\n",
    "    \n",
    "    raw_data = get_state_data(state.fips)\n",
    "    \n",
    "    variable_codes = raw_data[0]\n",
    "    values = raw_data[1]\n",
    "\n",
    "    data_df = pd.DataFrame({\n",
    "        \"Variable Code\": variable_codes,\n",
    "        \"Value\": values\n",
    "    })\n",
    "\n",
    "    data_df['Label'] = data_df['Variable Code'].map(dp03_mapping)\n",
    "    data_df = data_df[['Label', 'Value']].dropna()\n",
    "    \n",
    "    # Save the data with state-specific filename\n",
    "    filename = f\"{state.abbr.lower()}_dp03.csv\"\n",
    "    data_df.to_csv(os.path.join(raw_data_dir, filename), index=False)\n",
    "    print(f\"Saved {filename}\")\n",
    "\n",
    "print(\"All states processed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_structured_data(df):\n",
    "    def get_value(label):\n",
    "        return df[df[\"Label\"] == label][\"Value\"].values[0]\n",
    "\n",
    "    result = {\n",
    "        \"HEALTH INSURANCE COVERAGE\": {\n",
    "            \"Civilian noninstitutionalized population 19 to 64 years\": {\n",
    "                \"Total\": int(get_value(\"Estimate!!HEALTH INSURANCE COVERAGE!!Civilian noninstitutionalized population 19 to 64 years\")),\n",
    "                \"With health insurance coverage\": {\n",
    "                    \"Employed\": {\n",
    "                        \"count\": int(get_value(\"Estimate!!HEALTH INSURANCE COVERAGE!!Civilian noninstitutionalized population 19 to 64 years!!In labor force:!!Employed:!!With health insurance coverage\")),\n",
    "                        \"percentage\": float(get_value(\"Percent!!HEALTH INSURANCE COVERAGE!!Civilian noninstitutionalized population 19 to 64 years!!In labor force:!!Employed:!!With health insurance coverage\")),\n",
    "                        \"Private health insurance\": {\n",
    "                            \"count\": int(get_value(\"Estimate!!HEALTH INSURANCE COVERAGE!!Civilian noninstitutionalized population 19 to 64 years!!In labor force:!!Employed:!!With health insurance coverage!!With private health insurance\")),\n",
    "                            \"percentage\": float(get_value(\"Percent!!HEALTH INSURANCE COVERAGE!!Civilian noninstitutionalized population 19 to 64 years!!In labor force:!!Employed:!!With health insurance coverage!!With private health insurance\"))\n",
    "                        },\n",
    "                        \"Public coverage\": {\n",
    "                            \"count\": int(get_value(\"Estimate!!HEALTH INSURANCE COVERAGE!!Civilian noninstitutionalized population 19 to 64 years!!In labor force:!!Employed:!!With health insurance coverage!!With public coverage\")),\n",
    "                            \"percentage\": float(get_value(\"Percent!!HEALTH INSURANCE COVERAGE!!Civilian noninstitutionalized population 19 to 64 years!!In labor force:!!Employed:!!With health insurance coverage!!With public coverage\"))\n",
    "                        }\n",
    "                    },\n",
    "                    \"Unemployed\": {\n",
    "                        \"count\": int(get_value(\"Estimate!!HEALTH INSURANCE COVERAGE!!Civilian noninstitutionalized population 19 to 64 years!!In labor force:!!Unemployed:!!With health insurance coverage\")),\n",
    "                        \"percentage\": float(get_value(\"Percent!!HEALTH INSURANCE COVERAGE!!Civilian noninstitutionalized population 19 to 64 years!!In labor force:!!Unemployed:!!With health insurance coverage\")),\n",
    "                        \"Private health insurance\": {\n",
    "                            \"count\": int(get_value(\"Estimate!!HEALTH INSURANCE COVERAGE!!Civilian noninstitutionalized population 19 to 64 years!!In labor force:!!Unemployed:!!With health insurance coverage!!With private health insurance\")),\n",
    "                            \"percentage\": float(get_value(\"Percent!!HEALTH INSURANCE COVERAGE!!Civilian noninstitutionalized population 19 to 64 years!!In labor force:!!Unemployed:!!With health insurance coverage!!With private health insurance\"))\n",
    "                        },\n",
    "                        \"Public coverage\": {\n",
    "                            \"count\": int(get_value(\"Estimate!!HEALTH INSURANCE COVERAGE!!Civilian noninstitutionalized population 19 to 64 years!!In labor force:!!Unemployed:!!With health insurance coverage!!With public coverage\")),\n",
    "                            \"percentage\": float(get_value(\"Percent!!HEALTH INSURANCE COVERAGE!!Civilian noninstitutionalized population 19 to 64 years!!In labor force:!!Unemployed:!!With health insurance coverage!!With public coverage\"))\n",
    "                        }\n",
    "                    },\n",
    "                    \"Not in labor force\": {\n",
    "                        \"count\": int(get_value(\"Estimate!!HEALTH INSURANCE COVERAGE!!Civilian noninstitutionalized population 19 to 64 years!!Not in labor force:!!With health insurance coverage\")),\n",
    "                        \"percentage\": float(get_value(\"Percent!!HEALTH INSURANCE COVERAGE!!Civilian noninstitutionalized population 19 to 64 years!!Not in labor force:!!With health insurance coverage\")),\n",
    "                        \"Private health insurance\": {\n",
    "                            \"count\": int(get_value(\"Estimate!!HEALTH INSURANCE COVERAGE!!Civilian noninstitutionalized population 19 to 64 years!!Not in labor force:!!With health insurance coverage!!With private health insurance\")),\n",
    "                            \"percentage\": float(get_value(\"Percent!!HEALTH INSURANCE COVERAGE!!Civilian noninstitutionalized population 19 to 64 years!!Not in labor force:!!With health insurance coverage!!With private health insurance\"))\n",
    "                        },\n",
    "                        \"Public coverage\": {\n",
    "                            \"count\": int(get_value(\"Estimate!!HEALTH INSURANCE COVERAGE!!Civilian noninstitutionalized population 19 to 64 years!!Not in labor force:!!With health insurance coverage!!With public coverage\")),\n",
    "                            \"percentage\": float(get_value(\"Percent!!HEALTH INSURANCE COVERAGE!!Civilian noninstitutionalized population 19 to 64 years!!Not in labor force:!!With health insurance coverage!!With public coverage\"))\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                \"No health insurance coverage\": {\n",
    "                    \"Employed\": {\n",
    "                        \"count\": int(get_value(\"Estimate!!HEALTH INSURANCE COVERAGE!!Civilian noninstitutionalized population 19 to 64 years!!In labor force:!!Employed:!!No health insurance coverage\")),\n",
    "                        \"percentage\": float(get_value(\"Percent!!HEALTH INSURANCE COVERAGE!!Civilian noninstitutionalized population 19 to 64 years!!In labor force:!!Employed:!!No health insurance coverage\"))\n",
    "                    },\n",
    "                    \"Unemployed\": {\n",
    "                        \"count\": int(get_value(\"Estimate!!HEALTH INSURANCE COVERAGE!!Civilian noninstitutionalized population 19 to 64 years!!In labor force:!!Unemployed:!!No health insurance coverage\")),\n",
    "                        \"percentage\": float(get_value(\"Percent!!HEALTH INSURANCE COVERAGE!!Civilian noninstitutionalized population 19 to 64 years!!In labor force:!!Unemployed:!!No health insurance coverage\"))\n",
    "                    },\n",
    "                    \"Not in labor force\": {\n",
    "                        \"count\": int(get_value(\"Estimate!!HEALTH INSURANCE COVERAGE!!Civilian noninstitutionalized population 19 to 64 years!!Not in labor force:!!No health insurance coverage\")),\n",
    "                        \"percentage\": float(get_value(\"Percent!!HEALTH INSURANCE COVERAGE!!Civilian noninstitutionalized population 19 to 64 years!!Not in labor force:!!No health insurance coverage\"))\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"INCOME AND BENEFITS\": {\n",
    "            \"Total households\": int(get_value(\"Estimate!!INCOME AND BENEFITS (IN 2023 INFLATION-ADJUSTED DOLLARS)!!Total households\")),\n",
    "            \"Less than $10,000\": {\n",
    "                \"count\": int(get_value(\"Estimate!!INCOME AND BENEFITS (IN 2023 INFLATION-ADJUSTED DOLLARS)!!Total households!!Less than $10,000\")),\n",
    "                \"percentage\": float(get_value(\"Percent!!INCOME AND BENEFITS (IN 2023 INFLATION-ADJUSTED DOLLARS)!!Total households!!Less than $10,000\"))\n",
    "            },\n",
    "            \"$10,000 to $14,999\": {\n",
    "                \"count\": int(get_value(\"Estimate!!INCOME AND BENEFITS (IN 2023 INFLATION-ADJUSTED DOLLARS)!!Total households!!$10,000 to $14,999\")),\n",
    "                \"percentage\": float(get_value(\"Percent!!INCOME AND BENEFITS (IN 2023 INFLATION-ADJUSTED DOLLARS)!!Total households!!$10,000 to $14,999\"))\n",
    "            },\n",
    "            \"$15,000 to $24,999\": {\n",
    "                \"count\": int(get_value(\"Estimate!!INCOME AND BENEFITS (IN 2023 INFLATION-ADJUSTED DOLLARS)!!Total households!!$15,000 to $24,999\")),\n",
    "                \"percentage\": float(get_value(\"Percent!!INCOME AND BENEFITS (IN 2023 INFLATION-ADJUSTED DOLLARS)!!Total households!!$15,000 to $24,999\"))\n",
    "            },\n",
    "            \"$25,000 to $34,999\": {\n",
    "                \"count\": int(get_value(\"Estimate!!INCOME AND BENEFITS (IN 2023 INFLATION-ADJUSTED DOLLARS)!!Total households!!$25,000 to $34,999\")),\n",
    "                \"percentage\": float(get_value(\"Percent!!INCOME AND BENEFITS (IN 2023 INFLATION-ADJUSTED DOLLARS)!!Total households!!$25,000 to $34,999\"))\n",
    "            },\n",
    "            \"$35,000 to $49,999\": {\n",
    "                \"count\": int(get_value(\"Estimate!!INCOME AND BENEFITS (IN 2023 INFLATION-ADJUSTED DOLLARS)!!Total households!!$35,000 to $49,999\")),\n",
    "                \"percentage\": float(get_value(\"Percent!!INCOME AND BENEFITS (IN 2023 INFLATION-ADJUSTED DOLLARS)!!Total households!!$35,000 to $49,999\"))\n",
    "            },\n",
    "            \"$50,000 to $74,999\": {\n",
    "                \"count\": int(get_value(\"Estimate!!INCOME AND BENEFITS (IN 2023 INFLATION-ADJUSTED DOLLARS)!!Total households!!$50,000 to $74,999\")),\n",
    "                \"percentage\": float(get_value(\"Percent!!INCOME AND BENEFITS (IN 2023 INFLATION-ADJUSTED DOLLARS)!!Total households!!$50,000 to $74,999\"))\n",
    "            },\n",
    "            \"$75,000 to $99,999\": {\n",
    "                \"count\": int(get_value(\"Estimate!!INCOME AND BENEFITS (IN 2023 INFLATION-ADJUSTED DOLLARS)!!Total households!!$75,000 to $99,999\")),\n",
    "                \"percentage\": float(get_value(\"Percent!!INCOME AND BENEFITS (IN 2023 INFLATION-ADJUSTED DOLLARS)!!Total households!!$75,000 to $99,999\"))\n",
    "            },\n",
    "            \"$100,000 to $149,999\": {\n",
    "                \"count\": int(get_value(\"Estimate!!INCOME AND BENEFITS (IN 2023 INFLATION-ADJUSTED DOLLARS)!!Total households!!$100,000 to $149,999\")),\n",
    "                \"percentage\": float(get_value(\"Percent!!INCOME AND BENEFITS (IN 2023 INFLATION-ADJUSTED DOLLARS)!!Total households!!$100,000 to $149,999\"))\n",
    "            },\n",
    "            \"$150,000 to $199,999\": {\n",
    "                \"count\": int(get_value(\"Estimate!!INCOME AND BENEFITS (IN 2023 INFLATION-ADJUSTED DOLLARS)!!Total households!!$150,000 to $199,999\")),\n",
    "                \"percentage\": float(get_value(\"Percent!!INCOME AND BENEFITS (IN 2023 INFLATION-ADJUSTED DOLLARS)!!Total households!!$150,000 to $199,999\"))\n",
    "            },\n",
    "            \"$200,000 or more\": {\n",
    "                \"count\": int(get_value(\"Estimate!!INCOME AND BENEFITS (IN 2023 INFLATION-ADJUSTED DOLLARS)!!Total households!!$200,000 or more\")),\n",
    "                \"percentage\": float(get_value(\"Percent!!INCOME AND BENEFITS (IN 2023 INFLATION-ADJUSTED DOLLARS)!!Total households!!$200,000 or more\"))\n",
    "            },\n",
    "            \"Median household income (dollars)\": int(get_value(\"Estimate!!INCOME AND BENEFITS (IN 2023 INFLATION-ADJUSTED DOLLARS)!!Total households!!Median household income (dollars)\")),\n",
    "            \"Mean household income (dollars)\": int(get_value(\"Estimate!!INCOME AND BENEFITS (IN 2023 INFLATION-ADJUSTED DOLLARS)!!Total households!!Mean household income (dollars)\"))\n",
    "        }\n",
    "    }\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved structured data for ms\n",
      "Processed and saved structured data for sc\n",
      "Processed and saved structured data for de\n",
      "Processed and saved structured data for ma\n",
      "Processed and saved structured data for fl\n",
      "Processed and saved structured data for mo\n",
      "Processed and saved structured data for nc\n",
      "Processed and saved structured data for mi\n",
      "Processed and saved structured data for us\n",
      "Processed and saved structured data for id\n",
      "Processed and saved structured data for nj\n",
      "Processed and saved structured data for vt\n",
      "Processed and saved structured data for nv\n",
      "Processed and saved structured data for la\n",
      "Processed and saved structured data for tn\n",
      "Processed and saved structured data for ut\n",
      "Processed and saved structured data for ny\n",
      "Processed and saved structured data for md\n",
      "Processed and saved structured data for sd\n",
      "Processed and saved structured data for ia\n",
      "Processed and saved structured data for al\n",
      "Processed and saved structured data for wi\n",
      "Processed and saved structured data for ne\n",
      "Processed and saved structured data for ga\n",
      "Processed and saved structured data for nm\n",
      "Processed and saved structured data for or\n",
      "Processed and saved structured data for wv\n",
      "Processed and saved structured data for il\n",
      "Processed and saved structured data for wy\n",
      "Processed and saved structured data for hi\n",
      "Processed and saved structured data for ok\n",
      "Processed and saved structured data for ks\n",
      "Processed and saved structured data for ar\n",
      "Processed and saved structured data for co\n",
      "Processed and saved structured data for oh\n",
      "Processed and saved structured data for ri\n",
      "Processed and saved structured data for ky\n",
      "Processed and saved structured data for nd\n",
      "Processed and saved structured data for wa\n",
      "Processed and saved structured data for nh\n",
      "Processed and saved structured data for va\n",
      "Processed and saved structured data for mt\n",
      "Processed and saved structured data for in\n",
      "Processed and saved structured data for pa\n",
      "Processed and saved structured data for ak\n",
      "Processed and saved structured data for ct\n",
      "Processed and saved structured data for tx\n",
      "Processed and saved structured data for az\n",
      "Processed and saved structured data for mn\n",
      "Processed and saved structured data for ca\n",
      "Processed and saved structured data for me\n",
      "All states processed successfully!\n"
     ]
    }
   ],
   "source": [
    "# do this foimport os\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Directory containing the raw data files\n",
    "raw_data_dir = \"/user/al4263/Simulate/Persona/data/DP03/raw_data\"\n",
    "\n",
    "# Output directory for structured data\n",
    "output_dir = \"/user/al4263/Simulate/Persona/data/DP03/structured_data\"\n",
    "\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Process each state file\n",
    "for filename in os.listdir(raw_data_dir):\n",
    "    if filename.endswith(\"_dp03.csv\"):\n",
    "        state = filename.split(\"_\")[0]\n",
    "        \n",
    "        # Read the CSV file\n",
    "        data_df = pd.read_csv(os.path.join(raw_data_dir, filename))\n",
    "        \n",
    "        # Create the structured data\n",
    "        structured_data = create_structured_data(data_df)\n",
    "        \n",
    "        # Save the structured data as JSON\n",
    "        output_filename = f\"{state}_dp03_structured.json\"\n",
    "        with open(os.path.join(output_dir, output_filename), 'w') as f:\n",
    "            json.dump(structured_data, f, indent=2)\n",
    "        \n",
    "        print(f\"Processed and saved structured data for {state}\")\n",
    "\n",
    "print(\"All states processed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HouseHold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import us\n",
    "from get_dist.get_sex_race_age_dist import load_structured_data, get_sex_dist, get_age_dist, get_race_dist, sample_demographics\n",
    "from get_dist.get_household_dist import sample_household_type, sample_relationship\n",
    "from get_dist.get_marital_status_dist import sample_marital_status_by_gender\n",
    "from get_dist.get_veteran_dist import sample_veteran_status\n",
    "from get_dist.get_language_dist import sample_languages\n",
    "from get_dist.get_edu_dist import sample_education_level\n",
    "from get_dist.get_birth_dist import sample_birth_and_citizenship_multiple\n",
    "from get_dist.get_employment_dist import sample_labor_force_and_employment\n",
    "from get_dist.get_career_dist import generate_career\n",
    "\n",
    "def generate_personas_for_state(state):\n",
    "    # Load data\n",
    "    dp05 = f\"/user/al4263/Simulate/Persona/data/DP05/structured_data/{state.abbr.lower()}_structured_data.json\"\n",
    "    dp02 = f\"/user/al4263/Simulate/Persona/data/DP02/structured_data/{state.abbr.lower()}_dp02_structured.json\"\n",
    "    s2301 = f\"/user/al4263/Simulate/Persona/data/s2301/structured_data/{state.abbr.lower()}_s2301_structured.json\"\n",
    "    s2401 = f\"/user/al4263/Simulate/Persona/data/s2401/structured_data/{state.abbr.lower()}_s2401_structured.json\"\n",
    "\n",
    "    dp05_data = load_structured_data(dp05)\n",
    "    dp02_data = load_structured_data(dp02)\n",
    "    s2301_data = load_structured_data(s2301)\n",
    "    s2401_data = load_structured_data(s2401)\n",
    "\n",
    "    # Get distributions\n",
    "    age_distributions = get_age_dist(dp05_data)\n",
    "    sex_distributions = get_sex_dist(dp05_data)\n",
    "    race_distributions = get_race_dist(dp05_data)\n",
    "\n",
    "    # Sample demographics\n",
    "    num_samples = 1000\n",
    "    samples = [sample_demographics(age_distributions, sex_distributions, race_distributions) for _ in range(num_samples)]\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(samples)\n",
    "\n",
    "    # Add HOUSEHOLD_RELATIONSHIP\n",
    "    df['HOUSEHOLD_RELATIONSHIP'] = df.apply(lambda row: sample_relationship(dp02_data, dp05_data), axis=1)\n",
    "\n",
    "    # Sample household type for primary householders\n",
    "    def sample_household_type_for_primary(row):\n",
    "        if row['HOUSEHOLD_RELATIONSHIP'] == 'Primary Householder':\n",
    "            return sample_household_type(dp02_data, row['Sex'])\n",
    "        return None\n",
    "\n",
    "    df['HOUSEHOLD_TYPE'] = df.apply(sample_household_type_for_primary, axis=1)\n",
    "\n",
    "    # Sample additional attributes\n",
    "    df['MARITAL_STATUS'] = df.apply(lambda row: sample_marital_status_by_gender(dp02_data, row['Sex']), axis=1)\n",
    "    df['VETERAN_STATUS'] = df.apply(lambda row: sample_veteran_status(dp02_data), axis=1)\n",
    "    df['LANGUAGE'], df['ENGLISH_PROFICIENCY'] = zip(*df.apply(lambda row: sample_languages(dp02_data), axis=1))\n",
    "    df['EDUCATION'] = df.apply(lambda row: sample_education_level(dp02_data), axis=1)\n",
    "    df['BIRTH_PLACE'], df['CITIZENSHIP'], df['BIRTH_DETAIL'] = zip(*df.apply(lambda row: sample_birth_and_citizenship_multiple(dp02_data), axis=1))\n",
    "\n",
    "    # Sample employment status\n",
    "    df['Labor Force Status'], df['Employment Status'] = zip(*df['Age'].apply(lambda x: sample_labor_force_and_employment(x, s2301_data)))\n",
    "    df.columns = df.columns.str.upper()\n",
    "    df['CAREER'] = df.apply(lambda row: generate_career(row, s2401_data), axis=1)\n",
    "\n",
    "    # Add state information\n",
    "    df['STATE_NAME'] = state.name\n",
    "    df['STATE_ABBR'] = state.abbr\n",
    "\n",
    "    # upper case all the column names\n",
    "    df.columns = df.columns.str.upper()\n",
    "\n",
    "    # replace all null with \"NOT APPLICABLE\"\n",
    "    df.fillna(\"Not Applicable\", inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "state = us.states.CA\n",
    "df = generate_personas_for_state(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   AGE     SEX             RACE  LABOR FORCE STATUS  \\\n",
      "0       45 to 54 years    Male         Hispanic      In Labor Force   \n",
      "1    85 years and over    Male         Hispanic      In Labor Force   \n",
      "2       25 to 34 years    Male         Hispanic  Not in Labor Force   \n",
      "3       25 to 34 years  Female         Hispanic      In Labor Force   \n",
      "4       45 to 54 years    Male            White      In Labor Force   \n",
      "..                 ...     ...              ...                 ...   \n",
      "995     35 to 44 years    Male            White      In Labor Force   \n",
      "996     45 to 54 years  Female         Hispanic      In Labor Force   \n",
      "997     35 to 44 years  Female  Some Other Race      In Labor Force   \n",
      "998     35 to 44 years    Male         Hispanic  Not in Labor Force   \n",
      "999     35 to 44 years    Male            White      In Labor Force   \n",
      "\n",
      "    EMPLOYMENT STATUS            INSURANCE_COVERAGE          INCOME_RANGE  \n",
      "0            Employed               Public coverage  $150,000 to $199,999  \n",
      "1            Employed      Private health insurance      $200,000 or more  \n",
      "2      Not Applicable               Public coverage    $15,000 to $24,999  \n",
      "3            Employed      Private health insurance    $35,000 to $49,999  \n",
      "4            Employed  No health insurance coverage    $15,000 to $24,999  \n",
      "..                ...                           ...                   ...  \n",
      "995          Employed      Private health insurance    $50,000 to $74,999  \n",
      "996          Employed      Private health insurance    $50,000 to $74,999  \n",
      "997        Unemployed               Public coverage     Less than $10,000  \n",
      "998    Not Applicable               Public coverage    $75,000 to $99,999  \n",
      "999          Employed      Private health insurance  $150,000 to $199,999  \n",
      "\n",
      "[1000 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from collections import namedtuple\n",
    "\n",
    "CategoricalDistribution = namedtuple('CategoricalDistribution', ['categories', 'distribution'])\n",
    "\n",
    "def create_insurance_distribution(data, employment_status):\n",
    "    categories = ['Private health insurance', 'Public coverage', 'No health insurance coverage']\n",
    "    \n",
    "    if employment_status == 'Employed':\n",
    "        private = data['HEALTH INSURANCE COVERAGE']['Civilian noninstitutionalized population 19 to 64 years']['With health insurance coverage']['Employed']['Private health insurance']['percentage']\n",
    "        public = data['HEALTH INSURANCE COVERAGE']['Civilian noninstitutionalized population 19 to 64 years']['With health insurance coverage']['Employed']['Public coverage']['percentage']\n",
    "        none = data['HEALTH INSURANCE COVERAGE']['Civilian noninstitutionalized population 19 to 64 years']['No health insurance coverage']['Employed']['percentage']\n",
    "    elif employment_status == 'Unemployed':\n",
    "        private = data['HEALTH INSURANCE COVERAGE']['Civilian noninstitutionalized population 19 to 64 years']['With health insurance coverage']['Unemployed']['Private health insurance']['percentage']\n",
    "        public = data['HEALTH INSURANCE COVERAGE']['Civilian noninstitutionalized population 19 to 64 years']['With health insurance coverage']['Unemployed']['Public coverage']['percentage']\n",
    "        none = data['HEALTH INSURANCE COVERAGE']['Civilian noninstitutionalized population 19 to 64 years']['No health insurance coverage']['Unemployed']['percentage']\n",
    "    else:  # Not in labor force\n",
    "        private = data['HEALTH INSURANCE COVERAGE']['Civilian noninstitutionalized population 19 to 64 years']['With health insurance coverage']['Not in labor force']['Private health insurance']['percentage']\n",
    "        public = data['HEALTH INSURANCE COVERAGE']['Civilian noninstitutionalized population 19 to 64 years']['With health insurance coverage']['Not in labor force']['Public coverage']['percentage']\n",
    "        none = data['HEALTH INSURANCE COVERAGE']['Civilian noninstitutionalized population 19 to 64 years']['No health insurance coverage']['Not in labor force']['percentage']\n",
    "    \n",
    "    probabilities = torch.tensor([private, public, none]) / 100\n",
    "    return CategoricalDistribution(categories=categories, \n",
    "                                   distribution=torch.distributions.Categorical(probs=probabilities))\n",
    "\n",
    "def create_income_distribution(data):\n",
    "    categories = [\n",
    "        'Less than $10,000', '$10,000 to $14,999', '$15,000 to $24,999',\n",
    "        '$25,000 to $34,999', '$35,000 to $49,999', '$50,000 to $74,999',\n",
    "        '$75,000 to $99,999', '$100,000 to $149,999', '$150,000 to $199,999',\n",
    "        '$200,000 or more'\n",
    "    ]\n",
    "    probabilities = torch.tensor([\n",
    "        data['INCOME AND BENEFITS'][cat]['percentage'] for cat in categories\n",
    "    ]) / 100\n",
    "    return CategoricalDistribution(categories=categories, \n",
    "                                   distribution=torch.distributions.Categorical(probs=probabilities))\n",
    "\n",
    "def sample_insurance_and_income(row, data):\n",
    "    employment_status = row['EMPLOYMENT STATUS']\n",
    "    labor_force_status = row['LABOR FORCE STATUS']\n",
    "    \n",
    "    if labor_force_status == 'Not in Labor Force':\n",
    "        insurance_dist = create_insurance_distribution(data, 'Not in labor force')\n",
    "    else:\n",
    "        insurance_dist = create_insurance_distribution(data, employment_status)\n",
    "    \n",
    "    income_dist = create_income_distribution(data)\n",
    "    \n",
    "    insurance = insurance_dist.categories[insurance_dist.distribution.sample()]\n",
    "    income = income_dist.categories[income_dist.distribution.sample()]\n",
    "    \n",
    "    return insurance, income\n",
    "\n",
    "# Assuming 'data' is your dictionary with the census data\n",
    "# and 'df' is your DataFrame with the existing columns\n",
    "\n",
    "# Apply sampling to the DataFrame\n",
    "df[['INSURANCE_COVERAGE', 'INCOME_RANGE']] = df.apply(lambda row: sample_insurance_and_income(row, data), axis=1, result_type='expand')\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df[['AGE', 'SEX', 'RACE', 'LABOR FORCE STATUS', 'EMPLOYMENT STATUS', 'INSURANCE_COVERAGE', 'INCOME_RANGE']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Alabama...\n",
      "Saved al_s2301.csv\n",
      "Processing Alaska...\n",
      "Saved ak_s2301.csv\n",
      "Processing Arizona...\n",
      "Saved az_s2301.csv\n",
      "Processing Arkansas...\n",
      "Saved ar_s2301.csv\n",
      "Processing California...\n",
      "Saved ca_s2301.csv\n",
      "Processing Colorado...\n",
      "Saved co_s2301.csv\n",
      "Processing Connecticut...\n",
      "Saved ct_s2301.csv\n",
      "Processing Delaware...\n",
      "Saved de_s2301.csv\n",
      "Processing Florida...\n",
      "Saved fl_s2301.csv\n",
      "Processing Georgia...\n",
      "Saved ga_s2301.csv\n",
      "Processing Hawaii...\n",
      "Saved hi_s2301.csv\n",
      "Processing Idaho...\n",
      "Saved id_s2301.csv\n",
      "Processing Illinois...\n",
      "Saved il_s2301.csv\n",
      "Processing Indiana...\n",
      "Saved in_s2301.csv\n",
      "Processing Iowa...\n",
      "Saved ia_s2301.csv\n",
      "Processing Kansas...\n",
      "Saved ks_s2301.csv\n",
      "Processing Kentucky...\n",
      "Saved ky_s2301.csv\n",
      "Processing Louisiana...\n",
      "Saved la_s2301.csv\n",
      "Processing Maine...\n",
      "Saved me_s2301.csv\n",
      "Processing Maryland...\n",
      "Saved md_s2301.csv\n",
      "Processing Massachusetts...\n",
      "Saved ma_s2301.csv\n",
      "Processing Michigan...\n",
      "Saved mi_s2301.csv\n",
      "Processing Minnesota...\n",
      "Saved mn_s2301.csv\n",
      "Processing Mississippi...\n",
      "Saved ms_s2301.csv\n",
      "Processing Missouri...\n",
      "Saved mo_s2301.csv\n",
      "Processing Montana...\n",
      "Saved mt_s2301.csv\n",
      "Processing Nebraska...\n",
      "Saved ne_s2301.csv\n",
      "Processing Nevada...\n",
      "Saved nv_s2301.csv\n",
      "Processing New Hampshire...\n",
      "Saved nh_s2301.csv\n",
      "Processing New Jersey...\n",
      "Saved nj_s2301.csv\n",
      "Processing New Mexico...\n",
      "Saved nm_s2301.csv\n",
      "Processing New York...\n",
      "Saved ny_s2301.csv\n",
      "Processing North Carolina...\n",
      "Saved nc_s2301.csv\n",
      "Processing North Dakota...\n",
      "Saved nd_s2301.csv\n",
      "Processing Ohio...\n",
      "Saved oh_s2301.csv\n",
      "Processing Oklahoma...\n",
      "Saved ok_s2301.csv\n",
      "Processing Oregon...\n",
      "Saved or_s2301.csv\n",
      "Processing Pennsylvania...\n",
      "Saved pa_s2301.csv\n",
      "Processing Rhode Island...\n",
      "Saved ri_s2301.csv\n",
      "Processing South Carolina...\n",
      "Saved sc_s2301.csv\n",
      "Processing South Dakota...\n",
      "Saved sd_s2301.csv\n",
      "Processing Tennessee...\n",
      "Saved tn_s2301.csv\n",
      "Processing Texas...\n",
      "Saved tx_s2301.csv\n",
      "Processing Utah...\n",
      "Saved ut_s2301.csv\n",
      "Processing Vermont...\n",
      "Saved vt_s2301.csv\n",
      "Processing Virginia...\n",
      "Saved va_s2301.csv\n",
      "Processing Washington...\n",
      "Saved wa_s2301.csv\n",
      "Processing West Virginia...\n",
      "Saved wv_s2301.csv\n",
      "Processing Wisconsin...\n",
      "Saved wi_s2301.csv\n",
      "Processing Wyoming...\n",
      "Saved wy_s2301.csv\n",
      "All states processed successfully!\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Birth Place': 'Foreign Born', 'Citizenship': 'US Citizen', 'Region': 'Asia'}: 407\n",
      "{'Birth Place': 'US Born', 'Citizenship': 'US Citizen', 'Specific': 'State of residence'}: 6204\n",
      "{'Birth Place': 'US Born', 'Citizenship': 'US Citizen', 'Specific': 'Different state'}: 1283\n",
      "{'Birth Place': 'Foreign Born', 'Citizenship': 'Not a U.S. citizen', 'Region': 'Latin America'}: 444\n",
      "{'Birth Place': 'Foreign Born', 'Citizenship': 'US Citizen', 'Region': 'Europe'}: 205\n",
      "{'Birth Place': 'Foreign Born', 'Citizenship': 'Not a U.S. citizen', 'Region': 'Asia'}: 272\n",
      "{'Birth Place': 'Foreign Born', 'Citizenship': 'US Citizen', 'Region': 'Africa'}: 67\n",
      "{'Birth Place': 'Foreign Born', 'Citizenship': 'US Citizen', 'Region': 'Latin America'}: 664\n",
      "{'Birth Place': 'Foreign Born', 'Citizenship': 'Not a U.S. citizen', 'Region': 'Africa'}: 44\n",
      "{'Birth Place': 'Foreign Born', 'Citizenship': 'Not a U.S. citizen', 'Region': 'Europe'}: 142\n",
      "{'Birth Place': 'US Born', 'Citizenship': 'US Citizen', 'Specific': 'US territories or abroad to American parents'}: 233\n",
      "{'Birth Place': 'Foreign Born', 'Citizenship': 'US Citizen', 'Region': 'Northern America'}: 18\n",
      "{'Birth Place': 'Foreign Born', 'Citizenship': 'Not a U.S. citizen', 'Region': 'Northern America'}: 9\n",
      "{'Birth Place': 'Foreign Born', 'Citizenship': 'US Citizen', 'Region': 'Oceania'}: 5\n",
      "{'Birth Place': 'Foreign Born', 'Citizenship': 'Not a U.S. citizen', 'Region': 'Oceania'}: 3\n",
      "\n",
      "Percentages:\n",
      "{'Birth Place': 'Foreign Born', 'Citizenship': 'US Citizen', 'Region': 'Asia'}: 4.1%\n",
      "{'Birth Place': 'US Born', 'Citizenship': 'US Citizen', 'Specific': 'State of residence'}: 62.0%\n",
      "{'Birth Place': 'US Born', 'Citizenship': 'US Citizen', 'Specific': 'Different state'}: 12.8%\n",
      "{'Birth Place': 'Foreign Born', 'Citizenship': 'Not a U.S. citizen', 'Region': 'Latin America'}: 4.4%\n",
      "{'Birth Place': 'Foreign Born', 'Citizenship': 'US Citizen', 'Region': 'Europe'}: 2.1%\n",
      "{'Birth Place': 'Foreign Born', 'Citizenship': 'Not a U.S. citizen', 'Region': 'Asia'}: 2.7%\n",
      "{'Birth Place': 'Foreign Born', 'Citizenship': 'US Citizen', 'Region': 'Africa'}: 0.7%\n",
      "{'Birth Place': 'Foreign Born', 'Citizenship': 'US Citizen', 'Region': 'Latin America'}: 6.6%\n",
      "{'Birth Place': 'Foreign Born', 'Citizenship': 'Not a U.S. citizen', 'Region': 'Africa'}: 0.4%\n",
      "{'Birth Place': 'Foreign Born', 'Citizenship': 'Not a U.S. citizen', 'Region': 'Europe'}: 1.4%\n",
      "{'Birth Place': 'US Born', 'Citizenship': 'US Citizen', 'Specific': 'US territories or abroad to American parents'}: 2.3%\n",
      "{'Birth Place': 'Foreign Born', 'Citizenship': 'US Citizen', 'Region': 'Northern America'}: 0.2%\n",
      "{'Birth Place': 'Foreign Born', 'Citizenship': 'Not a U.S. citizen', 'Region': 'Northern America'}: 0.1%\n",
      "{'Birth Place': 'Foreign Born', 'Citizenship': 'US Citizen', 'Region': 'Oceania'}: 0.1%\n",
      "{'Birth Place': 'Foreign Born', 'Citizenship': 'Not a U.S. citizen', 'Region': 'Oceania'}: 0.0%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from collections import namedtuple, Counter\n",
    "\n",
    "CategoricalDistribution = namedtuple('CategoricalDistribution', ['categories', 'distribution'])\n",
    "\n",
    "def create_birth_place_distribution(birth_data):\n",
    "    categories = ['US Born', 'Foreign Born']\n",
    "    probabilities = torch.tensor([\n",
    "        birth_data['Native']['percentage'],\n",
    "        birth_data['Foreign born']['percentage']\n",
    "    ]) / 100  # Convert percentages to probabilities\n",
    "    return CategoricalDistribution(categories=categories, \n",
    "                                   distribution=torch.distributions.Categorical(probs=probabilities))\n",
    "\n",
    "def create_us_born_distribution(birth_data):\n",
    "    native_data = birth_data['Native']\n",
    "    total_native = native_data['count']\n",
    "    categories = ['State of residence', 'Different state', 'US territories or abroad to American parents']\n",
    "    probabilities = torch.tensor([\n",
    "        native_data['State of residence']['count'] / total_native,\n",
    "        native_data['Different state']['count'] / total_native,\n",
    "        native_data['Born in Puerto Rico, U.S. Island areas, or born abroad to American parent(s)   ']['count'] / total_native\n",
    "    ])\n",
    "    return CategoricalDistribution(categories=categories, \n",
    "                                   distribution=torch.distributions.Categorical(probs=probabilities))\n",
    "\n",
    "def create_foreign_born_distribution(birth_data):\n",
    "    foreign_data = birth_data['Foreign born']\n",
    "    categories = ['US Citizen', 'Not a U.S. citizen']\n",
    "    probabilities = torch.tensor([\n",
    "        foreign_data['US Citizen']['percentage'],\n",
    "        foreign_data['Not a U.S. citizen']['percentage']\n",
    "    ]) / 100  # Convert percentages to probabilities\n",
    "    return CategoricalDistribution(categories=categories, \n",
    "                                   distribution=torch.distributions.Categorical(probs=probabilities))\n",
    "\n",
    "def create_foreign_born_region_distribution(birth_data):\n",
    "    foreign_data = birth_data['Foreign born']\n",
    "    categories = ['Europe', 'Asia', 'Africa', 'Oceania', 'Latin America', 'Northern America']\n",
    "    probabilities = torch.tensor([foreign_data[cat]['percentage'] for cat in categories]) / 100\n",
    "    return CategoricalDistribution(categories=categories, \n",
    "                                   distribution=torch.distributions.Categorical(probs=probabilities))\n",
    "\n",
    "def sample_birth_and_citizenship(birth_data):\n",
    "    birth_place_dist = create_birth_place_distribution(birth_data)\n",
    "    us_born_dist = create_us_born_distribution(birth_data)\n",
    "    foreign_born_dist = create_foreign_born_distribution(birth_data)\n",
    "    foreign_region_dist = create_foreign_born_region_distribution(birth_data)\n",
    "\n",
    "    birth_place = sample_distribution(birth_place_dist)\n",
    "    \n",
    "    if birth_place == 'US Born':\n",
    "        us_birth_place = sample_distribution(us_born_dist)\n",
    "        return {'Birth Place': 'US Born', 'Specific': us_birth_place, 'Citizenship': 'US Citizen'}\n",
    "    else:\n",
    "        citizenship = sample_distribution(foreign_born_dist)\n",
    "        region = sample_distribution(foreign_region_dist)\n",
    "        return {'Birth Place': 'Foreign Born', 'Citizenship': citizenship, 'Region': region}\n",
    "\n",
    "def sample_distribution(distribution):\n",
    "    return distribution.categories[distribution.distribution.sample()]\n",
    "\n",
    "def sample_birth_and_citizenship_multiple(birth_data, num_samples=10000):\n",
    "    samples = [sample_birth_and_citizenship(birth_data) for _ in range(num_samples)]\n",
    "    return Counter(tuple(sorted(d.items())) for d in samples)\n",
    "\n",
    "# Usage example:\n",
    "birth_data = {\n",
    "    'Total': 19571216,\n",
    "    'Native': {'count': 15053220,\n",
    "     'percentage': 76.9,\n",
    "     'State of residence': {'count': 12146242, 'percentage': 62.1},\n",
    "     'Different state': {'count': 2429014, 'percentage': 12.4},\n",
    "     'Born in Puerto Rico, U.S. Island areas, or born abroad to American parent(s)   ': {'count': 477964,\n",
    "      'percentage': 2.4}},\n",
    "    'Foreign born': {'count': 4517996,\n",
    "     'percentage': 23.1,\n",
    "     'US Citizen': {'count': 2687784, 'percentage': 59.5},\n",
    "     'Not a U.S. citizen': {'count': 1830212, 'percentage': 40.5},\n",
    "     'Europe': {'count': 671383, 'percentage': 14.9},\n",
    "     'Asia': {'count': 1330190, 'percentage': 29.4},\n",
    "     'Africa': {'count': 223031, 'percentage': 4.9},\n",
    "     'Oceania': {'count': 17170, 'percentage': 0.4},\n",
    "     'Latin America': {'count': 2218060, 'percentage': 49.1},\n",
    "     'Northern America': {'count': 58109, 'percentage': 1.3}}\n",
    "}\n",
    "\n",
    "# Sample birth places and citizenship statuses\n",
    "sample_counts = sample_birth_and_citizenship_multiple(birth_data, num_samples=10000)\n",
    "\n",
    "# Print results\n",
    "for status, count in sample_counts.items():\n",
    "    print(f\"{dict(status)}: {count}\")\n",
    "\n",
    "# Optional: Calculate and print percentages\n",
    "total_samples = sum(sample_counts.values())\n",
    "print(\"\\nPercentages:\")\n",
    "for status, count in sample_counts.items():\n",
    "    percentage = (count / total_samples) * 100\n",
    "    print(f\"{dict(status)}: {percentage:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Race categories: ['White', 'Black or African American', 'American Indian and Alaska Native', 'Asian', 'Native Hawaiian and Other Pacific Islander', 'Some Other Race', 'Two or More Races']\n",
      "Race probabilities: [0.5509550955095509, 0.14311431143114312, 0.0067006700670067, 0.0912091209120912, 0.0004000400040004, 0.1028102810281028, 0.10481048104810481]\n",
      "Race distribution: tensor([5.5096e-01, 1.4311e-01, 6.7007e-03, 9.1209e-02, 4.0004e-04, 1.0281e-01,\n",
      "        1.0481e-01])\n",
      "\n",
      "American Indian and Alaska Native Ethnicities: ['Aztec', 'Blackfeet Tribe of the Blackfeet Indian Reservation of Montana', 'Maya', 'Native Village of Barrow Inupiat Traditional Government', 'Navajo Nation', 'Nome Eskimo Community', 'Other American Indian and Alaska Native']\n",
      "Probabilities: [0.19468053194680532, 0.013298670132986704, 0.10498950104989502, 0.0, 0.006399360063993601, 0.0, 0.6806319368063194]\n",
      "Distribution: tensor([0.1947, 0.0133, 0.1050, 0.0000, 0.0064, 0.0000, 0.6806])\n",
      "\n",
      "Asian Ethnicities: ['Asian Indian', 'Chinese', 'Filipino', 'Japanese', 'Korean', 'Vietnamese', 'Other Asian']\n",
      "Probabilities: [0.20472047204720473, 0.407940794079408, 0.06440644064406441, 0.017901790179017902, 0.0705070507050705, 0.017901790179017902, 0.21662166216621664]\n",
      "Distribution: tensor([0.2047, 0.4079, 0.0644, 0.0179, 0.0705, 0.0179, 0.2166])\n",
      "\n",
      "Native Hawaiian and Other Pacific Islander Ethnicities: ['Native Hawaiian', 'Chamorro', 'Samoan', 'Other Native Hawaiian and Other Pacific Islander']\n",
      "Probabilities: [0.2806280628062806, 0.11921192119211922, 0.23932393239323935, 0.36083608360836084]\n",
      "Distribution: tensor([0.2806, 0.1192, 0.2393, 0.3608])\n",
      "\n",
      "Two or More Races Combinations: ['White and Black or African American', 'White and American Indian and Alaska Native', 'White and Asian', 'White and Some Other Race', 'Black or African American and American Indian and Alaska Native', 'Black or African American and Some Other Race']\n",
      "Probabilities: [0.11900148181921805, 0.04411261826057221, 0.08594551464721303, 0.5906759375356206, 0.014704206086857402, 0.14556024165051862]\n",
      "Distribution: tensor([0.1190, 0.0441, 0.0859, 0.5907, 0.0147, 0.1456])\n",
      "\n",
      "Hispanic or Latino Categories: ['Hispanic or Latino (of any race)', 'Not Hispanic or Latino']\n",
      "Probabilities: [0.1978, 0.8022]\n",
      "Distribution: tensor([0.1978, 0.8022])\n",
      "\n",
      "Hispanic or Latino Subcategories: ['Mexican', 'Puerto Rican', 'Cuban', 'Other Hispanic or Latino']\n",
      "Probabilities: [0.13358664133586642, 0.24657534246575344, 0.022997700229977002, 0.5968403159684031]\n",
      "Distribution: tensor([0.1336, 0.2466, 0.0230, 0.5968])\n"
     ]
    }
   ],
   "source": [
    "race_data = data['RACE']\n",
    "main_race_categories = ['White', 'Black or African American', 'American Indian and Alaska Native', 'Asian', 'Native Hawaiian and Other Pacific Islander', 'Some Other Race', 'Two or More Races']\n",
    "\n",
    "race_counts = []\n",
    "race_percentages = []\n",
    "race_categories = []\n",
    "\n",
    "for category in main_race_categories:\n",
    "    if category in race_data:\n",
    "        count = race_data[category]['count']\n",
    "        percentage = race_data[category]['percentage']\n",
    "        race_counts.append(count)\n",
    "        race_percentages.append(percentage)\n",
    "        race_categories.append(category)\n",
    "    else:\n",
    "        print(f\"Category {category} not found in data\")\n",
    "\n",
    "# Normalize race percentages to sum to 1\n",
    "total_race_percentage = sum(race_percentages)\n",
    "race_probabilities = [p / total_race_percentage for p in race_percentages]\n",
    "race_probs_tensor = torch.tensor(race_probabilities)\n",
    "\n",
    "# Create Categorical distribution for Race\n",
    "race_distribution = torch.distributions.Categorical(probs=race_probs_tensor)\n",
    "\n",
    "print(\"\\nRace categories:\", race_categories)\n",
    "print(\"Race probabilities:\", race_probabilities)\n",
    "print(\"Race distribution:\", race_distribution.probs)\n",
    "\n",
    "# Process subcategories for races with ethnicities\n",
    "# For 'American Indian and Alaska Native'\n",
    "ai_an_ethnicities = race_data['American Indian and Alaska Native']['Ethnicities']\n",
    "\n",
    "ai_an_ethnicities_list = []\n",
    "ai_an_percentages = []\n",
    "\n",
    "for ethnicity, values in ai_an_ethnicities.items():\n",
    "    count = values['count']\n",
    "    percentage = values['percentage']\n",
    "    ai_an_ethnicities_list.append(ethnicity)\n",
    "    ai_an_percentages.append(percentage)\n",
    "\n",
    "# Normalize percentages\n",
    "total_ai_an_percentage = sum(ai_an_percentages)\n",
    "ai_an_probabilities = [p / total_ai_an_percentage for p in ai_an_percentages]\n",
    "ai_an_probs_tensor = torch.tensor(ai_an_probabilities)\n",
    "\n",
    "# Create Categorical distribution\n",
    "ai_an_distribution = torch.distributions.Categorical(probs=ai_an_probs_tensor)\n",
    "\n",
    "print(\"\\nAmerican Indian and Alaska Native Ethnicities:\", ai_an_ethnicities_list)\n",
    "print(\"Probabilities:\", ai_an_probabilities)\n",
    "print(\"Distribution:\", ai_an_distribution.probs)\n",
    "\n",
    "# For 'Asian'\n",
    "asian_ethnicities = race_data['Asian']['Ethnicities']\n",
    "\n",
    "asian_ethnicities_list = []\n",
    "asian_percentages = []\n",
    "\n",
    "for ethnicity, values in asian_ethnicities.items():\n",
    "    count = values['count']\n",
    "    percentage = values['percentage']\n",
    "    asian_ethnicities_list.append(ethnicity)\n",
    "    asian_percentages.append(percentage)\n",
    "\n",
    "# Normalize percentages\n",
    "total_asian_percentage = sum(asian_percentages)\n",
    "asian_probabilities = [p / total_asian_percentage for p in asian_percentages]\n",
    "asian_probs_tensor = torch.tensor(asian_probabilities)\n",
    "\n",
    "# Create Categorical distribution\n",
    "asian_distribution = torch.distributions.Categorical(probs=asian_probs_tensor)\n",
    "\n",
    "print(\"\\nAsian Ethnicities:\", asian_ethnicities_list)\n",
    "print(\"Probabilities:\", asian_probabilities)\n",
    "print(\"Distribution:\", asian_distribution.probs)\n",
    "\n",
    "# For 'Native Hawaiian and Other Pacific Islander'\n",
    "nhopi_ethnicities = race_data['Native Hawaiian and Other Pacific Islander']['Ethnicities']\n",
    "\n",
    "nhopi_ethnicities_list = []\n",
    "nhopi_percentages = []\n",
    "\n",
    "for ethnicity, values in nhopi_ethnicities.items():\n",
    "    count = values['count']\n",
    "    percentage = values['percentage']\n",
    "    nhopi_ethnicities_list.append(ethnicity)\n",
    "    nhopi_percentages.append(percentage)\n",
    "\n",
    "# Normalize percentages\n",
    "total_nhopi_percentage = sum(nhopi_percentages)\n",
    "nhopi_probabilities = [p / total_nhopi_percentage for p in nhopi_percentages]\n",
    "nhopi_probs_tensor = torch.tensor(nhopi_probabilities)\n",
    "\n",
    "# Create Categorical distribution\n",
    "nhopi_distribution = torch.distributions.Categorical(probs=nhopi_probs_tensor)\n",
    "\n",
    "print(\"\\nNative Hawaiian and Other Pacific Islander Ethnicities:\", nhopi_ethnicities_list)\n",
    "print(\"Probabilities:\", nhopi_probabilities)\n",
    "print(\"Distribution:\", nhopi_distribution.probs)\n",
    "\n",
    "# For 'Two or More Races'\n",
    "two_or_more_races = race_data['Two or More Races']['Combinations']\n",
    "\n",
    "combinations_list = []\n",
    "combinations_percentages = []\n",
    "\n",
    "for combination, values in two_or_more_races.items():\n",
    "    count = values['count']\n",
    "    percentage = values['percentage']\n",
    "    combinations_list.append(combination)\n",
    "    combinations_percentages.append(percentage)\n",
    "\n",
    "# Normalize percentages\n",
    "total_combinations_percentage = sum(combinations_percentages)\n",
    "combinations_probabilities = [p / total_combinations_percentage for p in combinations_percentages]\n",
    "combinations_probs_tensor = torch.tensor(combinations_probabilities)\n",
    "\n",
    "# Create Categorical distribution\n",
    "combinations_distribution = torch.distributions.Categorical(probs=combinations_probs_tensor)\n",
    "\n",
    "print(\"\\nTwo or More Races Combinations:\", combinations_list)\n",
    "print(\"Probabilities:\", combinations_probabilities)\n",
    "print(\"Distribution:\", combinations_distribution.probs)\n",
    "\n",
    "# Process 'HISPANIC OR LATINO AND RACE'\n",
    "hispanic_data = data['HISPANIC OR LATINO AND RACE']\n",
    "hispanic_categories = ['Hispanic or Latino (of any race)', 'Not Hispanic or Latino']\n",
    "\n",
    "hispanic_counts = []\n",
    "hispanic_percentages = []\n",
    "hispanic_categories_list = []\n",
    "\n",
    "for category in hispanic_categories:\n",
    "    if category in hispanic_data:\n",
    "        count = hispanic_data[category]['count']\n",
    "        percentage = hispanic_data[category]['percentage']\n",
    "        hispanic_counts.append(count)\n",
    "        hispanic_percentages.append(percentage)\n",
    "        hispanic_categories_list.append(category)\n",
    "\n",
    "# Normalize percentages\n",
    "total_hispanic_percentage = sum(hispanic_percentages)\n",
    "hispanic_probabilities = [p / total_hispanic_percentage for p in hispanic_percentages]\n",
    "hispanic_probs_tensor = torch.tensor(hispanic_probabilities)\n",
    "\n",
    "# Create Categorical distribution\n",
    "hispanic_distribution = torch.distributions.Categorical(probs=hispanic_probs_tensor)\n",
    "\n",
    "print(\"\\nHispanic or Latino Categories:\", hispanic_categories_list)\n",
    "print(\"Probabilities:\", hispanic_probabilities)\n",
    "print(\"Distribution:\", hispanic_distribution.probs)\n",
    "\n",
    "# Process 'Hispanic or Latino' subcategories\n",
    "hispanic_subcategories = hispanic_data['Hispanic or Latino']\n",
    "\n",
    "hispanic_subcategories_list = []\n",
    "hispanic_sub_percentages = []\n",
    "\n",
    "for subcategory, values in hispanic_subcategories.items():\n",
    "    if subcategory != 'count' and subcategory != 'percentage':\n",
    "        count = values['count']\n",
    "        percentage = values['percentage']\n",
    "        hispanic_subcategories_list.append(subcategory)\n",
    "        hispanic_sub_percentages.append(percentage)\n",
    "\n",
    "# Normalize percentages\n",
    "total_hispanic_sub_percentage = sum(hispanic_sub_percentages)\n",
    "hispanic_sub_probabilities = [p / total_hispanic_sub_percentage for p in hispanic_sub_percentages]\n",
    "hispanic_sub_probs_tensor = torch.tensor(hispanic_sub_probabilities)\n",
    "\n",
    "# Create Categorical distribution\n",
    "hispanic_sub_distribution = torch.distributions.Categorical(probs=hispanic_sub_probs_tensor)\n",
    "\n",
    "print(\"\\nHispanic or Latino Subcategories:\", hispanic_subcategories_list)\n",
    "print(\"Probabilities:\", hispanic_sub_probabilities)\n",
    "print(\"Distribution:\", hispanic_sub_distribution.probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Race        Ethnicity       Age Group     Sex\n",
      "0              Asian     Asian Indian  45 to 54 years    Male\n",
      "1              White            White  35 to 44 years  Female\n",
      "2           Hispanic            Cuban  35 to 44 years  Female\n",
      "3              White            White  35 to 44 years    Male\n",
      "4              White            White  35 to 44 years    Male\n",
      "..               ...              ...             ...     ...\n",
      "995  Some Other Race  Some Other Race  65 to 74 years    Male\n",
      "996            White            White  65 to 74 years    Male\n",
      "997            White            White  35 to 44 years  Female\n",
      "998            White            White  60 to 64 years  Female\n",
      "999            White            White  35 to 44 years  Female\n",
      "\n",
      "[1000 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def sample_demographics():\n",
    "    hispanic_status = hispanic_categories_list[hispanic_distribution.sample().item()]\n",
    "    \n",
    "    race = None\n",
    "    ethnicity = None\n",
    "    \n",
    "    if hispanic_status == 'Hispanic or Latino (of any race)':\n",
    "        hispanic_subtype = hispanic_subcategories_list[hispanic_sub_distribution.sample().item()]\n",
    "        race = 'Hispanic'\n",
    "        ethnicity = hispanic_subtype\n",
    "    else:\n",
    "        race = race_categories[race_distribution.sample().item()]\n",
    "        \n",
    "        if race == 'American Indian and Alaska Native':\n",
    "            ethnicity = ai_an_ethnicities_list[ai_an_distribution.sample().item()]\n",
    "        elif race == 'Asian':\n",
    "            ethnicity = asian_ethnicities_list[asian_distribution.sample().item()]\n",
    "        elif race == 'Native Hawaiian and Other Pacific Islander':\n",
    "            ethnicity = nhopi_ethnicities_list[nhopi_distribution.sample().item()]\n",
    "        elif race == 'Two or More Races':\n",
    "            ethnicity = combinations_list[combinations_distribution.sample().item()]\n",
    "    \n",
    "    age_group = age_categories[age_distribution.sample().item()]\n",
    "    sex = sex_categories[sex_distribution.sample().item()]\n",
    "\n",
    "    return {\n",
    "        'Race': race,\n",
    "        'Ethnicity': ethnicity if ethnicity else race,\n",
    "        'Age Group': age_group,\n",
    "        'Sex': sex\n",
    "    }\n",
    "\n",
    "# Sample 100 demographic profiles\n",
    "num_samples = 1000\n",
    "samples = [sample_demographics() for _ in range(num_samples)]\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(samples)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Race probabilities:\n",
      "Original: {'White': 0.5509550955095509, 'Black or African American': 0.14311431143114312, 'American Indian and Alaska Native': 0.0067006700670067, 'Asian': 0.0912091209120912, 'Native Hawaiian and Other Pacific Islander': 0.0004000400040004, 'Some Other Race': 0.1028102810281028, 'Two or More Races': 0.10481048104810481}\n",
      "Sampled: {'White': 0.479, 'Hispanic': 0.183, 'Black or African American': 0.107, 'Two or More Races': 0.08, 'Some Other Race': 0.08, 'Asian': 0.066, 'American Indian and Alaska Native': 0.004, 'Native Hawaiian and Other Pacific Islander': 0.001}\n",
      "\n",
      "Age Group probabilities:\n",
      "Original: {'18 to 19 years': 0.025699999999999997, '20 to 24 years': 0.0789, '25 to 34 years': 0.175, '35 to 44 years': 0.1634, '45 to 54 years': 0.1515, '55 to 59 years': 0.08199999999999999, '60 to 64 years': 0.0842, '65 to 74 years': 0.1334, '75 to 84 years': 0.0726, '85 years and over': 0.0268}\n",
      "Sampled: {'35 to 44 years': 0.164, '25 to 34 years': 0.162, '45 to 54 years': 0.145, '65 to 74 years': 0.136, '60 to 64 years': 0.091, '55 to 59 years': 0.087, '20 to 24 years': 0.084, '75 to 84 years': 0.069, '18 to 19 years': 0.032, '85 years and over': 0.03}\n",
      "\n",
      "Sex probabilities:\n",
      "Original: {'Male': 0.48200000000000004, 'Female': 0.518}\n",
      "Sampled: {'Male': 0.507, 'Female': 0.493}\n",
      "\n",
      "Hispanic proportion:\n",
      "Original: 0.1978\n",
      "Sampled: 0.183\n",
      "\n",
      "Hispanic subtypes probabilities:\n",
      "Original: {'Mexican': 0.13358664133586642, 'Puerto Rican': 0.24657534246575344, 'Cuban': 0.022997700229977002, 'Other Hispanic or Latino': 0.5968403159684031}\n",
      "Sampled: {'Other Hispanic or Latino': 0.6775956284153005, 'Puerto Rican': 0.17486338797814208, 'Mexican': 0.1366120218579235, 'Cuban': 0.01092896174863388}\n"
     ]
    }
   ],
   "source": [
    "# Calculate probabilities from the sampled data\n",
    "sampled_probabilities = {\n",
    "    'Race': df['Race'].value_counts(normalize=True),\n",
    "    'Age Group': df['Age Group'].value_counts(normalize=True),\n",
    "    'Sex': df['Sex'].value_counts(normalize=True)\n",
    "}\n",
    "\n",
    "# Compare with original probabilities\n",
    "print(\"Race probabilities:\")\n",
    "print(\"Original:\", dict(zip(race_categories, race_probabilities)))\n",
    "print(\"Sampled:\", sampled_probabilities['Race'].to_dict())\n",
    "print()\n",
    "\n",
    "print(\"Age Group probabilities:\")\n",
    "print(\"Original:\", dict(zip(age_categories, age_probabilities)))\n",
    "print(\"Sampled:\", sampled_probabilities['Age Group'].to_dict())\n",
    "print()\n",
    "\n",
    "print(\"Sex probabilities:\")\n",
    "print(\"Original:\", dict(zip(sex_categories, sex_probabilities)))\n",
    "print(\"Sampled:\", sampled_probabilities['Sex'].to_dict())\n",
    "print()\n",
    "\n",
    "# Calculate Hispanic proportion\n",
    "hispanic_proportion = (df['Race'] == 'Hispanic').mean()\n",
    "print(\"Hispanic proportion:\")\n",
    "print(\"Original:\", hispanic_probabilities[0])\n",
    "print(\"Sampled:\", hispanic_proportion)\n",
    "print()\n",
    "\n",
    "# For Hispanic subtypes\n",
    "if 'Hispanic' in df['Race'].unique():\n",
    "    hispanic_subtypes = df[df['Race'] == 'Hispanic']['Ethnicity'].value_counts(normalize=True)\n",
    "    print(\"Hispanic subtypes probabilities:\")\n",
    "    print(\"Original:\", dict(zip(hispanic_subcategories_list, hispanic_sub_probabilities)))\n",
    "    print(\"Sampled:\", hispanic_subtypes.to_dict())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
